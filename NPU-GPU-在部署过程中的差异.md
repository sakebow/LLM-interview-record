---
title: 面试记录：NPU和GPU在部署过程中的差异
date: 2025-09-09 09:27:50
categories:
  - interview
tags:
  - LLM
  - interview
mathjax: true
---

# 前言

这个问题看起来有点广泛，但是我们可以一点点作答。

<!-- more -->

# 容量

这个是最直观的差异了。`H20`有$96GB$显存，而昇腾的`910B`有$64GB$。这也就意味着，如果用两张卡同时部署模型的话，`H20`可以有更多的显存剩余，也就能够获得更高的并发量。

# 计算精度

目前来说，按照昇腾官方的说法，在推理服务部署过程中，最高支持的精度只有`fp16`（较多支持）或者`bf16`（较少支持）；相对的，`H20`最高支持`fp64`，在能力上`H20`能力偏高。

# 软件栈

对于`H20`来说，社区支持更为广泛，基于`CUDA`/`cuDNN`+`PyTorch`/`Tensorflow`的解决方案能够涵盖到工程与学术的各个方面，功能支持也相对更为完善，包括`function call`；相对的，`910B`在部署服务上，主要采用`CANN`+`MindSpore`，在算子的处理上有独特的处理方式，包括图编译引擎（`GE`）等。同时，`function call`仅有`ChatGLM-6B`支持，生态相对贫乏。

# 多租户分割

对于`H20`，基于原生`MIG`的支持，可以很方便地将单卡分解为多个实例，在多业务隔离上有着巨大的优势；相对的，`910B`没有对应的支持，只能够以容器作为对象，构成虚拟化的隔离方案。

# 集群处理

在服务器内，`H20`主要由`NVLink`赋能，带宽规格约为$900GB/s$；而`910B`主要主要由`HCCS`处理，链路双向带宽最高$60GB/s$。

而在服务器外，`H20`使用`NCCL`，与`NVLink`是同一个体系；`910B`使用`HCCL`，与`HCCS`是同一个体系。

# 调优

在优化上，`H20`可以使用`vLLm`，实现更为精细的显存块，处理合适的情况下，可以获得极致的性能；相对的，`910B`的优化主要依赖其中的`GE`，因此优化过程相对来说更平台化，比如修改`npuMemSize`可以直接影响到`KVCache`的显存占用。